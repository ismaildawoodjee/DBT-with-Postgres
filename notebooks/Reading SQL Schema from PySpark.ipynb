{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514686bf-bd89-4a0c-a3ce-e1b97381e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe35101-1c25-41d3-9883-fce4a32225c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27469230-8712-49c7-9651-db887186f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39b4ddb5-1f8f-4182-aaa4-70b97f8e2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = \"sourcedb1\"\n",
    "PASS_WORD = \"sourcedb1\"\n",
    "HOST_NAME = \"postgres-source\"\n",
    "DB_NAME = \"sourcedb\"\n",
    "\n",
    "CONN_STRING = f\"postgresql+psycopg2://{USER_NAME}:{PASS_WORD}@{HOST_NAME}/{DB_NAME}\"\n",
    "engine = create_engine(CONN_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e704a6d-c2b6-4d4b-849e-248890a070b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = \"pyspark_postgres\"\n",
    "master = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44661b4-95cd-4109-94c9-40514ad45c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/07 09:49:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(master) \\\n",
    "        .appName(appName) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b9511-936c-460a-9f50-e50eda98dee7",
   "metadata": {},
   "source": [
    "## Customers Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d5c332-78c6-4475-8f18-497929cffd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = pd.read_sql('SELECT * FROM ecommerce.customers', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "453dde26-c84b-4b74-873a-c3511536cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_sdf = spark.createDataFrame(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64f9193e-64b8-4269-a5a7-adf073f3b50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(customer_id,StringType,true),StructField(customer_unique_id,StringType,true),StructField(customer_zip_code_prefix,StringType,true),StructField(customer_city,StringType,true),StructField(customer_state,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(customers_sdf.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b6c97-0246-458b-b3fb-fc5e01777dd0",
   "metadata": {},
   "source": [
    "## Orders Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6ecbe8-2852-4c83-b355-0335e3197470",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = pd.read_sql('SELECT * FROM ecommerce.orders', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d4d3fcf-7263-4b3b-95a4-be344c4a9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_sdf = spark.createDataFrame(orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "797a9f1a-5bfc-46e5-a92d-b3716d8df677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(order_id,StringType,true),StructField(customer_id,StringType,true),StructField(order_status,StringType,true),StructField(order_purchase_timestamp,TimestampType,true),StructField(order_approved_at,TimestampType,true),StructField(order_delivered_carrier_date,TimestampType,true),StructField(order_delivered_customer_date,TimestampType,true),StructField(order_estimated_delivery_date,TimestampType,true)))\n"
     ]
    }
   ],
   "source": [
    "pprint(orders_sdf.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24832a6d-686f-4c67-a27f-135ef96996e3",
   "metadata": {},
   "source": [
    "## Output as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc8fa426-47cf-49a7-889c-d7ae5a7c74af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/07 10:15:42 WARN TaskSetManager: Stage 4 contains a task of very large size (9655 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "customers_sdf.write.parquet('/filesystem/customers.parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8f113-4a9c-4d04-acb3-f0558188aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_sdf.write.parquet('/filesystem/orders.parquet', compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
